import tensorflow as tf
import numpy as np
import cv2
import json
import os

# MoveNet ëª¨ë¸ ë¡œë”©
interpreter = tf.lite.Interpreter(model_path="movenet/4.tflite")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# ê°ë„ ê³„ì‚°ìš© í‚¤í¬ì¸íŠ¸ ì •ì˜
ANGLE_DEFINITIONS = {
    "left_elbow": [5, 7, 9],
    "right_elbow": [6, 8, 10],
    "left_knee": [11, 13, 15],
    "right_knee": [12, 14, 16],
    "back": [5, 11, 15]
}

# ê°ë„ ê³„ì‚° í•¨ìˆ˜
def calculate_angle(a, b, c):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    ab = a - b
    cb = c - b
    cosine = np.dot(ab, cb) / (np.linalg.norm(ab) * np.linalg.norm(cb))
    angle = np.arccos(np.clip(cosine, -1.0, 1.0))
    return np.degrees(angle)

# í‚¤í¬ì¸íŠ¸ë¥¼ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
def get_point(keypoints, index, shape):
    y, x, c = keypoints[index]
    h, w, _ = shape
    return (int(x * w), int(y * h)), c

# ê°ë„ ì¸¡ì • í•¨ìˆ˜
def get_angles(keypoints, shape):
    angles = {}
    for name, idx in ANGLE_DEFINITIONS.items():
        p1, c1 = get_point(keypoints, idx[0], shape)
        p2, c2 = get_point(keypoints, idx[1], shape)
        p3, c3 = get_point(keypoints, idx[2], shape)
        if min(c1, c2, c3) > 0.3:
            angles[name] = int(calculate_angle(p1, p2, p3))
    return angles

# ì›¹ìº  ì‹œì‘
cap = cv2.VideoCapture(0)

print("âœ… ì›í•˜ëŠ” ìì„¸ë¥¼ ì¡ê³  's' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ê¸°ì¤€ JSONì´ ì €ì¥ë©ë‹ˆë‹¤.")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    input_image = tf.image.resize_with_pad(tf.expand_dims(image_rgb, axis=0), 192, 192)
    input_image = tf.cast(input_image, dtype=tf.uint8)

    interpreter.set_tensor(input_details[0]['index'], input_image.numpy())
    interpreter.invoke()
    keypoints = interpreter.get_tensor(output_details[0]['index'])[0][0]

    # ê´€ì ˆ ë° ê°ë„ í‘œì‹œ
    for name, idx in ANGLE_DEFINITIONS.items():
        p1, c1 = get_point(keypoints, idx[0], frame.shape)
        p2, c2 = get_point(keypoints, idx[1], frame.shape)
        p3, c3 = get_point(keypoints, idx[2], frame.shape)

        if min(c1, c2, c3) > 0.3:
            # ì„  ì—°ê²°
            cv2.line(frame, p1, p2, (255, 0, 0), 2)
            cv2.line(frame, p3, p2, (255, 0, 0), 2)

            # ì› ê·¸ë¦¬ê¸°
            cv2.circle(frame, p1, 5, (0, 255, 0), -1)
            cv2.circle(frame, p2, 5, (0, 255, 0), -1)
            cv2.circle(frame, p3, 5, (0, 255, 0), -1)

            # ê°ë„ í‘œì‹œ
            angle = int(calculate_angle(p1, p2, p3))
            cv2.putText(frame, f'{angle}Â°', (p2[0] + 10, p2[1] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

    cv2.imshow("ê¸°ì¤€ ìì„¸ ìº¡ì²˜ê¸°", frame)

    key = cv2.waitKey(10)
    if key & 0xFF == ord('s'):
        # ê°ë„ ì¸¡ì • ë° ì €ì¥
        angles = get_angles(keypoints, frame.shape)
        template = {
            "name": input("ğŸ’¾ ì €ì¥í•  ìì„¸ ì´ë¦„: "),
            "angles": angles,
            "tolerance": 15
        }
        os.makedirs("pose_data", exist_ok=True)
        filename = f"pose_data/{template['name']}.json"
        with open(filename, "w") as f:
            json.dump(template, f, indent=2)
        print(f"âœ… {filename} ì €ì¥ ì™„ë£Œ!")
    elif key & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
